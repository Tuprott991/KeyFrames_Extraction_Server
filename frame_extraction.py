
import os
import sys

sys.path.append("/home/tuktu/KeyFrames_Extraction_Server/TransNetV2/inference")

from transnetv2 import TransNetV2

import numpy as np
import tensorflow as tf
import cv2
import json
import imagehash
from PIL import Image
import csv

def calculate_image_hash(frame):
    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Chuy·ªÉn frame th√†nh ƒë·ªãnh d·∫°ng ·∫£nh
    return imagehash.phash(image)  # S·ª≠ d·ª•ng phash ƒë·ªÉ t√≠nh to√°n hash c·ªßa h√¨nh ·∫£nh

# H√†m t√≠nh kho·∫£ng c√°ch Hamming gi·ªØa hai gi√° tr·ªã hash
def hamming_distance(hash1, hash2):
    return hash1 - hash2

# ...
def is_blurry(frame, threshold=100):
    # Chuy·ªÉn ƒë·ªïi ·∫£nh sang grayscale (·∫£nh x√°m)
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # T√≠nh to√°n ƒë·ªô bi·∫øn thi√™n c·ªßa Laplacian
    laplacian_var = cv2.Laplacian(gray_frame, cv2.CV_64F).var()
    
    # N·∫øu ƒë·ªô bi·∫øn thi√™n th·∫•p h∆°n ng∆∞·ª°ng threshold, coi nh∆∞ frame b·ªã m·ªù
    return laplacian_var < threshold

# ...
def format_csv_file(frame_idx, n, fps):
    pts_time = round(frame_idx / fps, 2)
    new_dict = {
        'n': n,
        'pts_time': pts_time,
        'fps': fps,
        'frame_idx': frame_idx
    }
    return new_dict

# ..
def save_to_csv(csv_file, output_folder, file_name):
    # ƒê·∫£m b·∫£o file_name c√≥ ph·∫ßn m·ªü r·ªông .csv
    if not file_name.endswith('.csv'):
        file_name += '.csv'
    
    # ƒê·∫£m b·∫£o th∆∞ m·ª•c output_folder t·ªìn t·∫°i
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    
    # ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß t·ªõi file
    file_path = os.path.join(output_folder, file_name)
    
    # M·ªü file csv v√† ghi n·ªôi dung
    with open(file_path, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=['n', 'pts_time', 'fps', 'frame_idx'])
        writer.writeheader()
        writer.writerows(csv_file)
    
    print(f"File saved at: {file_path}")

# ========== CONFIG ==========
# Ng∆∞·ª°ng l·ªçc tr√πng
HAMMING_THRESHOLD = 5
# Ng∆∞·ª°ng chuy·ªÉn c·∫£nh
KEYFRAME_PROB_THRESHOLD = 0.2
# Load model
model = TransNetV2()    

def extract_frames(video_path, resize_shape=(48, 27), skip_start=5, skip_end=10):
    """ƒê·ªçc to√†n b·ªô frame t·ª´ video v√† resize ƒë·ªÉ d√πng cho TransNetV2, b·ªè qua skip_start gi√¢y ƒë·∫ßu v√† skip_end gi√¢y cu·ªëi"""
    frames = [] # M·∫£ng l∆∞u c√°c frame ti·ªÅn x·ª≠ l√Ω
    
    # ƒê·ªçc video
    cap = cv2.VideoCapture(video_path)

    # L·∫•y frame ·ªü skip_start gi√¢y ƒë·∫ßu v√† skip_end gi√¢y cu·ªëi
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    start_frame = int(fps * skip_start)
    end_frame = max(start_frame, total_frames - int(fps * skip_end))  # tr√°nh √¢m


    for frame_idx in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            break # K·∫øt th√∫c n·∫øu kh√¥ng c√≤n frame n√†o ƒë·ªÉ ƒë·ªçc
        # Print frame shape for debugging
        if start_frame <= frame_idx < end_frame:
            # Chuy·ªÉn ƒë·ªïi m√†u s·∫Øc t·ª´ BGR sang RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # ƒê·ªïi k√≠ch th∆∞·ªõc frame ƒë·ªÉ ph·ª•c v·ª• cho vi·ªác d·ª± ƒëo√°n
            frame_resized = cv2.resize(frame_rgb, resize_shape)
            # Th√™m frame ƒë√£ thay ƒë·ªïi v√†o m·∫£ng
            frames.append(frame_resized)

    # Gi·∫£i ph√≥ng video ƒë√£ ƒë·ªçc
    cap.release()
    
    # Chuy·ªÉn to√†n b·ªô frame v·ªÅ m·∫£ng Numpy r·ªìi tr·∫£ v·ªÅ
    return np.array(frames), fps, start_frame, end_frame


def detect_scene_changes(model, frames, threshold=KEYFRAME_PROB_THRESHOLD):
    """Ph√°t hi·ªán ƒëi·ªÉm chuy·ªÉn c·∫£nh b·∫±ng TransNetV2"""
    # prediction: x√°c su·∫•t cho t·ª´ng frame.
    # prediction_changes: x√°c su·∫•t thay ƒë·ªïi c·∫£nh gi·ªØa 2 frame li√™n ti·∫øp.
    prediction, prediction_changes = model.predict_frames(frames)

    # T√¨m ch·ªâ s·ªë x√°c su·∫•t thay ƒë·ªïi c·∫£nh gi·ªØa 2 frame li√™n ti·∫øp l·ªõn h∆°n ng∆∞·ª°ng
    # N√≥ s·∫Ω l∆∞u frame m√† thay ƒë·ªïi nhi·ªÅu so v·ªõi frame tr∆∞·ªõc ƒë√≥.
    raw_scene_changes = np.where(prediction_changes > threshold)[0]

    # L·ªçc nhi·ªÖu (b·ªè c√°c thay ƒë·ªïi li√™n ti·∫øp nhau)
    scene_changes = []
    for i in range(1, len(raw_scene_changes)):
        if raw_scene_changes[i] - raw_scene_changes[i - 1] > 1:
            scene_changes.append(raw_scene_changes[i - 1])
    if len(raw_scene_changes) > 0:
        # Ki·ªÉm tra c·∫£ ƒëi·ªÉm chuy·ªÉn c·∫£nh cu·ªëi c√πng sau khi k·∫øt th√∫c v√≤ng l·∫∑p
        scene_changes.append(raw_scene_changes[-1])

    # X√≥a c√°c ch·ªâ s·ªë c·∫£nh m√† tr√πng l·∫∑p v√† s·∫Øp x·∫øp l·∫°i theo th·ª© t·ª± tƒÉng d·∫ßn r·ªìi tr·∫£ v·ªÅ
    return sorted(set(scene_changes))


def extract_keyframes(video_path, scene_changes, frames, fps, start_frame, end_frame):
    """Tr√≠ch xu·∫•t frame ƒë·∫ßu/gi·ªØa/cu·ªëi c·ªßa m·ªói ƒëo·∫°n"""
    # count: Bi·∫øn ƒë·∫øm l∆∞u t√™n file
    frame_index, count = 0, 0
    # csv_entries: File map-keyframe
    current_segment, keyframes, csv_entries = [], {}, []
    
    # ƒê·ªçc video
    cap = cv2.VideoCapture(video_path)

    while True:
        ret, frame = cap.read()
        if not ret:
            break # K·∫øt th√∫c n·∫øu kh√¥ng c√≤n frame n√†o ƒë·ªÉ ƒë·ªçc

        # B·ªè qua v√†i gi√¢y ƒë·∫ßu
        if frame_index < start_frame:
            frame_index += 1
            continue

        # T√≠nh frame_index t∆∞∆°ng ·ª©ng v·ªõi frames ƒë√£ skip
        relative_index = frame_index - start_frame
        
        # N·∫øu ƒë·∫øn ƒëi·ªÉm chuy·ªÉn c·∫£nh ho·∫∑c frame cu·ªëi
        if relative_index in scene_changes or relative_index == len(frames) - 1:
            # N·∫øu c√≥ tr√™n 2 khung h√¨nh trong list th√¨ l·∫•y ƒë·∫ßu gi·ªØa v√† cu·ªëi, sau ƒë√≥ reset list
            if len(current_segment) > 2:
                # L·∫•y khung h√¨nh ƒë·∫ßu, gi·ªØa v√† cu·ªëi
                start, mid, end = (
                    current_segment[0],
                    current_segment[len(current_segment) // 2],
                    current_segment[-1],
                )

                keyframes[count] = start
                keyframes[count + 1] = mid
                keyframes[count + 2] = end

                # Th√™m d·ªØ li·ªáu v√†o file map-keyframe
                csv_entries.extend([
                    format_csv_file(frame_index - len(current_segment), count, fps),
                    format_csv_file(frame_index - len(current_segment) + len(current_segment) // 2, count + 1, fps),
                    format_csv_file(frame_index - 1, count + 2, fps),
                ])

                count += 3

            # Reset danh s√°ch khung h√¨nh hi·ªán t·∫°i
            current_segment = []

        # Th√™m khung h√¨nh hi·ªán t·∫°i v√†o danh s√°ch current_frames
        current_segment.append(frame)
        frame_index += 1

    # Gi·∫£i ph√≥ng video ƒë√£ ƒë·ªçc
    cap.release()
    
    return keyframes, csv_entries


def filter_duplicate_frames(frames_dict, threshold=HAMMING_THRESHOLD):
    """L·ªçc frame tr√πng l·∫∑p b·∫±ng Hamming Distance"""
    filtered, prev_hash = {}, None
    
    for idx, frame in frames_dict.items():
        # T√≠nh hash c·ªßa frame hi·ªán t·∫°i
        cur_hash = calculate_image_hash(frame)

        # N·∫øu ƒë√¢y l√† frame ƒë·∫ßu ti√™n ho·∫∑c kho·∫£ng c√°ch Hamming l·ªõn h∆°n ng∆∞·ª°ng
        if prev_hash is None or hamming_distance(cur_hash, prev_hash) > threshold:
            # L∆∞u frame v√†o k·∫øt qu·∫£ sau khi l·ªçc
            filtered[idx] = frame
            # C·∫≠p nh·∫≠t hash c·ªßa frame hi·ªán t·∫°i
            prev_hash = cur_hash
            
    return filtered


def save_frames(frames_dict, output_folder):
    """L∆∞u keyframes th√†nh file ·∫£nh"""
    for idx, frame in frames_dict.items():
        output_path = os.path.join(output_folder, f"{str(idx).zfill(3)}.jpg")
        cv2.imwrite(output_path, frame)


# ========== MAIN PIPELINE ==========
def process_videos(input_folder, output_folder, csv_output_folder, model):
    # T·∫°o c√°c folder output n·∫øu ch∆∞a c√≥
    os.makedirs(output_folder, exist_ok=True)
    os.makedirs(csv_output_folder, exist_ok=True)

    # Duy·ªát qua t·∫•t c·∫£ c√°c file trong th∆∞ m·ª•c input
    for video_file in sorted(os.listdir(input_folder)):
        if not video_file.endswith(".mp4") or video_file == "L25_V012.mp4" or video_file == "K01_V001.mp4" or video_file == "K01_V002.mp4":
            print(f"B·ªè qua file {video_file}")
            continue

        # T·∫°o ƒë∆∞·ªùng d·∫´n video
        video_path = os.path.join(input_folder, video_file)
        video_name = os.path.splitext(video_file)[0]  # L·∫•y t√™n video kh√¥ng bao g·ªìm ph·∫ßn m·ªü r·ªông
        output_video_folder = os.path.join(output_folder, video_name)
        os.makedirs(output_video_folder, exist_ok=True)

        try:
            print(f"ƒêang x·ª≠ l√Ω video: {video_name}")

            # Extract frames
            frames, fps, start_frame, end_frame = extract_frames(video_path)

            # Print frames shape
            print(f"Extracted {len(frames)} frames with shape {frames.shape} (if frames exist)")


            # Scene detection (using model in config)
            scene_changes = detect_scene_changes(model, frames)

            # Keyframe extraction (xu·∫•t keyframes)
            keyframes, csv_entries = extract_keyframes(video_path, scene_changes, frames, fps, start_frame, end_frame)

            # Remove duplicates (l·ªçc ·∫£nh tr√πng)
            filtered_frames = filter_duplicate_frames(keyframes)

            # Save results
            save_frames(filtered_frames, output_video_folder)
            save_to_csv(csv_entries, csv_output_folder, video_name)

            print(f"‚úÖ X·ª≠ l√Ω xong video: {video_name}")

        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω video {video_name}: {e}")
            continue

# Process all video folders from Videos_K01 to Videos_K20
for k in range(1, 21):  # 1 to 20 inclusive
    folder_name = f"Videos_K{k:02d}"  # Format as K01, K02, ..., K20
    input_folder = f"/home/tuktu/KeyFrames_Extraction_Server/{folder_name}/video"
    output_folder = f"/home/tuktu/KeyFrames_Extraction_Server/output/images/{folder_name}"
    csv_output_folder = f"/home/tuktu/KeyFrames_Extraction_Server/output/csv/{folder_name}"
    
    print(f"\n{'='*50}")
    print(f"Processing folder: {folder_name}")
    print(f"{'='*50}")
    
    # Check if input folder exists before processing
    if not os.path.exists(input_folder):
        print(f"‚ö†Ô∏è  Input folder does not exist: {input_folder}")
        continue
    
    try:
        process_videos(
            input_folder=input_folder,
            output_folder=output_folder,
            csv_output_folder=csv_output_folder,
            model=model
        )
        print(f"‚úÖ Completed processing folder: {folder_name}")
    except Exception as e:
        print(f"‚ùå Error processing folder {folder_name}: {e}")
        continue

print(f"\n{'='*50}")
print("üéâ All video folders processing completed!")
print(f"{'='*50}")